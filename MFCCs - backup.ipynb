{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Procesamiento de habla para Learning Machine:</center>\n",
    "# Mel-Frecuency Ceptral Coefficients (MFCCs)\n",
    "\n",
    "El reconocimiento de habla  hoy en día es una herramienta muy utilizada para la interacción con la tecnología en general, desde el ámbito de entretenimiento al ámbito profesional.\n",
    "\n",
    "Metodología:\n",
    "Para que una máquina logre identificar un sonido hablado, es necesario entender el cómo los seres humanos decodificamos los sonidos hablados.\n",
    "\n",
    "MFCCs: en base a lo anterior, los MFCCs por lo tanto representan con presición este fin. Actualmente son muy utilizados para el reconocimiento del habla. \n",
    "\n",
    "A continuación se presenta el código necesario para obtener los MFCCs de la base de datos <a href=\"https://link.springer.com/article/10.1007/s10579-015-9324-5\">KALAKA3</a>\n",
    "\n",
    "## Pasos para la creación de MFCCs\n",
    "1. Organización del dataset\n",
    "2. Lectura y obtención de MFCCs\n",
    "    - i. Obtención de las señales en Numpy Arrays\n",
    "    - ii. Separar la señal de audio en frames.\n",
    "    - iii. Cálculo del periodograma estimado de la potencia de la señal\n",
    "    - iv. Aplicar el filtro mel, sumar la energía en cada filtro\n",
    "    - v. Obtención del logaritmo de las energías del filterbank\n",
    "    - vi. Obtención de la DCT\n",
    "    - vii.Guardar los coeficientes (2-13) de la DCT, descartar lo demás\n",
    "3. Creación de la red de entrenamiento\n",
    "4. Análisis de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Organización del dataset\n",
    "En primer lugar es necesario organizar el dataset de la siguiente manera:\n",
    "- KALAKA3\n",
    "    - DEV_KALAKA3\n",
    "    - EVAL_KALAKA3\\eval\\data\n",
    "    - TRAIN_KALAKA3\\data\n",
    "        - Basque\n",
    "            - clean\n",
    "            - noisy\n",
    "        - ....\n",
    "            ....\n",
    "        - Spanish\n",
    "            - clean\n",
    "            - noisy\n",
    "                - 0a7707a3.wav\n",
    "                - ...\n",
    "                - ff5e57c3.wav\n",
    "                \n",
    "### Carga de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file includes routines for basic signal processing including framing and computing power spectra.\n",
    "# Author: James Lyons 2012\n",
    "import decimal\n",
    "import numpy\n",
    "import math\n",
    "import logging\n",
    "import os\n",
    "from scipy.fftpack import dct\n",
    "from scipy.io.wavfile import read as readwav\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificación de Paths\n",
    "Esta sección es muy importante para que el método de creación de los MFCCs pueda iterar de manera correcta, tanto para la lecutra de los audios, como para el grabado de los MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SOURCE = 'KALAKA3-XANDER' \n",
    "OUTPUT = 'MFCCS-XANDER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file includes routines for basic signal processing including framing and computing power spectra.\n",
    "# Author: James Lyons 2012\n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "\n",
    "def rolling_window(a, window, step=1):\n",
    "    # http://ellisvalentiner.com/post/2017-03-21-np-strides-trick\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
    "\n",
    "\n",
    "def framesig(sig, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,)), stride_trick=True):\n",
    "    \"\"\"Frame a signal into overlapping frames.\n",
    "    :param sig: the audio signal to frame.\n",
    "    :param frame_len: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n",
    "    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n",
    "    \"\"\"\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step))\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = numpy.zeros((padlen - slen,))\n",
    "    padsignal = numpy.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
    "    else:\n",
    "        indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "            numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "        indices = numpy.array(indices, dtype=numpy.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "\n",
    "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,))):\n",
    "    \"\"\"Does overlap-add procedure to undo the action of framesig.\n",
    "    :param frames: the array of frames.\n",
    "    :param siglen: the length of the desired signal, use 0 if unknown. Output will be truncated to siglen samples.\n",
    "    :param frame_len: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :returns: a 1-D signal.\n",
    "    \"\"\"\n",
    "    frame_len = round_half_up(frame_len)\n",
    "    frame_step = round_half_up(frame_step)\n",
    "    numframes = numpy.shape(frames)[0]\n",
    "    assert numpy.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "        numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "    indices = numpy.array(indices, dtype=numpy.int32)\n",
    "    padlen = (numframes - 1) * frame_step + frame_len\n",
    "\n",
    "    if siglen <= 0: siglen = padlen\n",
    "\n",
    "    rec_signal = numpy.zeros((padlen,))\n",
    "    window_correction = numpy.zeros((padlen,))\n",
    "    win = winfunc(frame_len)\n",
    "\n",
    "    for i in range(0, numframes):\n",
    "        window_correction[indices[i, :]] = window_correction[\n",
    "                                               indices[i, :]] + win + 1e-15  # add a little bit so it is never zero\n",
    "        rec_signal[indices[i, :]] = rec_signal[indices[i, :]] + frames[i, :]\n",
    "\n",
    "    rec_signal = rec_signal / window_correction\n",
    "    return rec_signal[0:siglen]\n",
    "\n",
    "\n",
    "def magspec(frames, NFFT):\n",
    "    \"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    if numpy.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            numpy.shape(frames)[1], NFFT)\n",
    "    complex_spec = numpy.fft.rfft(frames, NFFT)\n",
    "    return numpy.absolute(complex_spec)\n",
    "\n",
    "\n",
    "def powspec(frames, NFFT):\n",
    "    \"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    return 1.0 / NFFT * numpy.square(magspec(frames, NFFT))\n",
    "\n",
    "\n",
    "def logpowspec(frames, NFFT, norm=1):\n",
    "    \"\"\"Compute the log power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :param norm: If norm=1, the log power spectrum is normalised so that the max value (across all frames) is 0.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the log power spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    ps = powspec(frames, NFFT);\n",
    "    ps[ps <= 1e-30] = 1e-30\n",
    "    lps = 10 * numpy.log10(ps)\n",
    "    if norm:\n",
    "        return lps - numpy.max(lps)\n",
    "    else:\n",
    "        return lps\n",
    "\n",
    "\n",
    "def preemphasis(signal, coeff=0.95):\n",
    "    \"\"\"perform preemphasis on the input signal.\n",
    "    :param signal: The signal to filter.\n",
    "    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n",
    "    :returns: the filtered signal.\n",
    "    \"\"\"\n",
    "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate filterbank features. Provides e.g. fbank and mfcc features for use in ASR applications\n",
    "# Author: James Lyons 2012\n",
    "\n",
    "def calculate_nfft(samplerate, winlen):\n",
    "    \"\"\"Calculates the FFT size as a power of two greater than or equal to\n",
    "    the number of samples in a single window length.\n",
    "    \n",
    "    Having an FFT less than the window length loses precision by dropping\n",
    "    many of the samples; a longer FFT than the window allows zero-padding\n",
    "    of the FFT buffer which is neutral in terms of frequency domain conversion.\n",
    "    :param samplerate: The sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: The length of the analysis window in seconds.\n",
    "    \"\"\"\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft\n",
    "\n",
    "def mfcc(signal,samplerate=16000,winlen=0.025,winstep=0.01,numcep=13,\n",
    "         nfilt=26,nfft=None,lowfreq=0,highfreq=None,preemph=0.97,ceplifter=22,appendEnergy=True,\n",
    "         winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute MFCC features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param numcep: the number of cepstrum to return, default 13\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is None, which uses the calculate_nfft function to choose the smallest size that does not drop sample data.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n",
    "    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    nfft = nfft or calculate_nfft(samplerate, winlen)\n",
    "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
    "    feat = numpy.log(feat)\n",
    "    feat = dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
    "    feat = lifter(feat,ceplifter)\n",
    "    if appendEnergy: feat[:,0] = numpy.log(energy) # replace first cepstral coefficient with log of frame energy\n",
    "    return feat\n",
    "\n",
    "def fbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "          nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "          winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute Mel-filterbank energy features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n",
    "        second return value is the energy in each frame (total energy, unwindowed)\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    signal = preemphasis(signal,preemph)\n",
    "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
    "    pspec = powspec(frames,nfft)\n",
    "    energy = numpy.sum(pspec,1) # this stores the total energy in each frame\n",
    "    energy = numpy.where(energy == 0,numpy.finfo(float).eps,energy) # if energy is zero, we get problems with log\n",
    "\n",
    "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
    "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
    "    feat = numpy.where(feat == 0,numpy.finfo(float).eps,feat) # if feat is zero, we get problems with log\n",
    "\n",
    "    return feat,energy\n",
    "\n",
    "def logfbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "             nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "             winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute log Mel-filterbank energy features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
    "    return numpy.log(feat)\n",
    "\n",
    "def ssc(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "        nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "        winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute Spectral Subband Centroid features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    signal = preemphasis(signal,preemph)\n",
    "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
    "    pspec = powspec(frames,nfft)\n",
    "    pspec = numpy.where(pspec == 0,numpy.finfo(float).eps,pspec) # if things are all zeros we get problems\n",
    "\n",
    "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
    "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
    "    R = numpy.tile(numpy.linspace(1,samplerate/2,numpy.size(pspec,1)),(numpy.size(pspec,0),1))\n",
    "\n",
    "    return numpy.dot(pspec*R,fb.T) / feat\n",
    "\n",
    "def hz2mel(hz):\n",
    "    \"\"\"Convert a value in Hertz to Mels\n",
    "    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 2595 * numpy.log10(1+hz/700.)\n",
    "\n",
    "def mel2hz(mel):\n",
    "    \"\"\"Convert a value in Mels to Hertz\n",
    "    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "\n",
    "def get_filterbanks(nfilt=20,nfft=512,samplerate=16000,lowfreq=0,highfreq=None):\n",
    "    \"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n",
    "    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n",
    "    :param nfilt: the number of filters in the filterbank, default 20.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz. Affects mel spacing.\n",
    "    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n",
    "    :param highfreq: highest band edge of mel filters, default samplerate/2\n",
    "    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel(lowfreq)\n",
    "    highmel = hz2mel(highfreq)\n",
    "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    bin = numpy.floor((nfft+1)*mel2hz(melpoints)/samplerate)\n",
    "\n",
    "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bin[j]), int(bin[j+1])):\n",
    "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "    return fbank\n",
    "\n",
    "def lifter(cepstra, L=22):\n",
    "    \"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n",
    "    magnitude of the high frequency DCT coeffs.\n",
    "    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n",
    "    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n",
    "    \"\"\"\n",
    "    if L > 0:\n",
    "        nframes,ncoeff = numpy.shape(cepstra)\n",
    "        n = numpy.arange(ncoeff)\n",
    "        lift = 1 + (L/2.)*numpy.sin(numpy.pi*n/L)\n",
    "        return lift*cepstra\n",
    "    else:\n",
    "        # values of L <= 0, do nothing\n",
    "        return cepstra\n",
    "\n",
    "def delta(feat, N):\n",
    "    \"\"\"Compute delta features from a feature vector sequence.\n",
    "    :param feat: A numpy array of size (NUMFRAMES by number of features) containing features. Each row holds 1 feature vector.\n",
    "    :param N: For each frame, calculate delta features based on preceding and following N frames\n",
    "    :returns: A numpy array of size (NUMFRAMES by number of features) containing delta features. Each row holds 1 delta feature vector.\n",
    "    \"\"\"\n",
    "    if N < 1:\n",
    "        raise ValueError('N must be an integer >= 1')\n",
    "    NUMFRAMES = len(feat)\n",
    "    denominator = 2 * sum([i**2 for i in range(1, N+1)])\n",
    "    delta_feat = numpy.empty_like(feat)\n",
    "    padded = numpy.pad(feat, ((N, N), (0, 0)), mode='edge')   # padded version of feat\n",
    "    for t in range(NUMFRAMES):\n",
    "        delta_feat[t] = numpy.dot(numpy.arange(-N, N+1), padded[t : t+2*N+1]) / denominator   # [t : t+2*N+1] == [(N+t)-N : (N+t)+N+1]\n",
    "    return delta_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotMfcc(filter_banks):\n",
    "    plt.subplot(312)\n",
    "    filter_banks -= (numpy.mean(filter_banks,axis=0) + 1e-8)\n",
    "    plt.imshow(filter_banks.T, cmap=plt.cm.jet, aspect='auto')\n",
    "    plt.xticks(numpy.arange(0, (filter_banks.T).shape[1],\n",
    "    int((filter_banks.T).shape[1] / 4)),\n",
    "    ['0s', '0.5s', '1s', '1.5s','2.5s','3s','3.5'])\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis()\n",
    "    plt.title('Imagen del Espectro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los MFCCs\n",
    "El siguiente bucle lee y crea los MFCCs desde el SOURCE especificado, luego crea una carpeta con el nombre OUTPUT con la misma estructura del dataset de los archivos de audio (WAVs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for root, dirs, files in os.walk( SOURCE ):\n",
    "\n",
    "    for archivo in files:\n",
    "        if archivo.endswith('wav'):\n",
    "            output_dir = root.replace( SOURCE, OUTPUT   )\n",
    "            output_filename = archivo.split('.')[0]\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            input_path = \"{}/{}\".format( root,archivo ) #DIRECCION DEL ARCHIVO WAV A PROCESAR\n",
    "            output_path = \"{}/{}.mfccs\".format( output_dir, output_filename ) #DIRECCION DONDE SE VA A GUARDAR EL ARCHIVO DE MFCC\n",
    "            print(\"{}: {} {}\".format(i,input_path,output_path))#SE IMPRIME ORIGEN Y DESTINO \n",
    "            i+=1\n",
    "            _, input= readwav(input_path) #SE LEE EL ARCHIVO DE AUDIO Y SE GUARDA COMO UN ARRAY DE NUMPY\n",
    "\n",
    "            output = mfcc( input )\n",
    "            d_mfcc_feat = delta(output, 2)\n",
    "            fbank_feat = logfbank(sig,rate)\n",
    "            \n",
    "            print(output.shape)\n",
    "            output.tofile( output_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los MFCCs para su procesamiento\n",
    "A continuacion se elaborara un metodo para compactar los MFCCs en un archivo csv, que es un poco mas versatil que guardarlo por separado\n",
    "\n",
    "### Construccion del training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basque\n",
      "Catalan\n",
      "English\n",
      "Galician\n",
      "Portuguese\n",
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "# make a new folder in this directory to save our results in\n",
    "MUESTRAS=100 #cuantos MFCCs se van a evaluar del total del CORPUS\n",
    "#Para contar el numero de nuestras a evaluar\n",
    "i=0\n",
    "\n",
    "TRAINDIR=\"MFCCS/TRAIN_KALAKA3/data\"\n",
    "X_TRAIN=[]\n",
    "Y_TRAIN=[]\n",
    "if not os.path.exists(TRAINDIR):\n",
    "    print(\"No se encuentra ningun MFCC\")\n",
    "    sys.exit()\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "\n",
    "#se almacenará en esta variable los mfccs y sus etiquetas\n",
    "for idioma in os.listdir(TRAINDIR):\n",
    "  \n",
    "    sourceMFCC=TRAINDIR+\"/\"+idioma\n",
    "    print(idioma)\n",
    "\n",
    "    for root, dirs, files in os.walk( sourceMFCC):\n",
    "        #if i==MUESTRAS:\n",
    "        #    break\n",
    "        for archivo in files:\n",
    "            if archivo.endswith('mfccs'): # only get MFCCs \n",
    "                mfccFile = root + \"/\" + os.path.splitext(archivo)[0] + \".mfccs\"\n",
    "                \n",
    "                #Tomo la lista de mfccs de un archivo de audio y lo convierto a un arreglo\n",
    "                mfccLst=numpy.fromfile(mfccFile)\n",
    "                #Como cada mfcc es de una longitud de 13 lo redimensiono\n",
    "                mfccFrames=mfccLst.reshape(int(mfccLst.shape[0]/13),13)\n",
    "                #for frame in mfccFrames:\n",
    "                #la salida le añado a mi lista de MFCC\n",
    "                X_TRAIN.append(mfccFrames)#almaceno el MFCC\n",
    "                Y_TRAIN.append(idioma)#almaceno el idioma al que pertenece el MFCC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basque\n",
      "Catalan\n",
      "English\n",
      "Galician\n",
      "Portuguese\n",
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "# make a new folder in this directory to save our results in\n",
    "MUESTRAS=20 #cuantos MFCCs se van a evaluar\n",
    "#Para contar el numero de nuestras a evaluar\n",
    "i=0\n",
    "\n",
    "# make a new folder in this directory to save our results in\n",
    "\n",
    "TESTDIR=\"MFCCS/TEST_KALAKA3/data\"\n",
    "X_TEST=[]\n",
    "Y_TEST=[]\n",
    "if not os.path.exists(TESTDIR):\n",
    "    print(\"No se encuentra ningun MFCC\")\n",
    "    sys.exit()\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "#se almacenará en esta variable los mfccs y sus etiquetas\n",
    "for idioma in os.listdir(TESTDIR):\n",
    "  \n",
    "    sourceMFCC=TESTDIR+\"/\"+idioma\n",
    "    print(idioma)\n",
    "\n",
    "    for root, dirs, files in os.walk( sourceMFCC):\n",
    "        #if i==MUESTRAS:\n",
    "        #    break\n",
    "        for archivo in files:\n",
    "            if archivo.endswith('mfccs'): # only get MFCCs \n",
    "                mfccFile = root + \"/\" + os.path.splitext(archivo)[0] + \".mfccs\"\n",
    "                #print(mfccFile)\n",
    "                #Establezco el label del MFCC \n",
    "                mfccLst=numpy.fromfile(mfccFile)\n",
    "                #print(mfcc.shape)\n",
    "                mfccFrames=mfccLst.reshape(int(mfccLst.shape[0]/13),13)\n",
    "                #print(mfccFrames.shape)\n",
    "                #print(mfccFrames[0])\n",
    "                #for frame in mfccFrames:\n",
    "                X_TEST.append(mfccFrames)#almaceno el MFCC\n",
    "                Y_TEST.append(idioma)#almaceno el idioma al que pertenece el MFCC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obteniendo un mfcc para pruebas\n",
    "mfccTmp=numpy.fromfile(\"MFCCS/TRAIN_KALAKA3/data/Basque\\clean/00248e27.mfccs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#Metodos a utilizar\n",
    "#mfcc\n",
    "#delta\n",
    "#logfbank\n",
    "#Obteniendo el mfcc de un wav para compararlo con el Mfcc anterior\n",
    "import scipy.io.wavfile as wav\n",
    "(rate,sig) = wav.read(\"KALAKA3/TRAIN_KALAKA3/data\\Catalan\\clean/1a8b426c.wav\")\n",
    "\n",
    "mfcc_feat = mfcc(sig,rate)\n",
    "print(mfcc_feat.shape)\n",
    "print(mfcc_feat[2])\n",
    "print(mfcc_feat[20])\n",
    "d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "fbank_feat = logfbank(sig,rate)\n",
    "plotMfcc(mfcc_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mfcc_feat.shape)\n",
    "print(mfcc_feat[0])\n",
    "print(d_mfcc_feat.shape)\n",
    "print(fbank_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mfccFrames=mfccTmp.reshape(int(mfccTmp.shape[0]/13),13) \n",
    "print(mfccTmp.shape)\n",
    "print(mfccFrames.shape)\n",
    "print(mfccFrames[0])\n",
    "#plotMfcc(mfccFrames)\n",
    "d_mfcc_feat = delta(mfccFrames, 2)\n",
    "fbank_feat = logfbank(sig,rate)\n",
    "plotMfcc(fbank_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconicimiento Automático del habla (ASR)\n",
    "### Carga de los mfccs\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se convierten a arrays las listas obtenidas\n",
    "X_TRAIN=numpy.asarray(X_TRAIN)\n",
    "Y_TRAIN=numpy.asarray(Y_TRAIN)\n",
    "X_TEST=numpy.asarray(X_TEST)\n",
    "Y_TEST=numpy.asarray(Y_TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de los MFCCs es muy variado, es decir que, existen audios desde los 400 MFCCs y otros que tienen 20000MFCCs, por ello es necesario trabajar con un numero exacto de MFCCs por audio. Esto tiene sentido para trabajar con redes neuronales CNN, por ejemplo cuando se trabajaba con imagenes, éstas debian ser muestreadas a un solo tamaño por ejemplo 28x28, en este caso lo haremos con MFCCs promedio del dataset. Las muestras menores, se rellenaran con ceros, las muestras superiores se cortaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3726,)\n",
      "Galician\n",
      "Promedio del tamaño de MFCCs en los audios: 8831\n"
     ]
    }
   ],
   "source": [
    "#obtengo el minimo numero de MFCCs\n",
    "def average_len(l):\n",
    "  return sum(map(len, l))/float(len(l))\n",
    "numMFCCs=round(sum(map(len, X_TRAIN))/float(len(X_TRAIN)))\n",
    "print(X_TRAIN.shape)\n",
    "print(Y_TRAIN[2000])\n",
    "print(\"Promedio del tamaño de MFCCs en los audios: \"+str(numMFCCs))\n",
    "\n",
    "numMFCCs=14000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellenando y quitando MFCCs según el caso, este proceso podía haberse hecho en el caso de generar el Train, por motivos de aprendizaje lo hacemos después"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fitMFFCs(mfccs_data):\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    \n",
    "  \n",
    "    mfccsFit=[]\n",
    "    for mfccs_audio in mfccs_data:\n",
    "        #print(mfccs_audio)\n",
    "        #print(mfccs_audio.shape[0])\n",
    "        if (numMFCCs > mfccs_audio.shape[0]):\n",
    "            pad_width = numMFCCs - mfccs_audio.shape[0]\n",
    "            #print(\"ENTRO\")\n",
    "            #print(mfccs_audio.shape)\n",
    "            mfccs_audio = numpy.pad(mfccs_audio, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
    "            \n",
    "\n",
    "        # Else cutoff the remaining parts\n",
    "        else:\n",
    "            #print(\"-----------------------------\")\n",
    "            #print(mfccs_audio.shape)\n",
    "            mfccs_audio = mfccs_audio[:numMFCCs, :]\n",
    "            #print(mfccs_audio.shape)\n",
    "            #print(\"-----------------------------\")\n",
    "        #print(mfccs_audio.shape)\n",
    "        mfccsFit.append(mfccs_audio)\n",
    "        #print(\"-----------------------------\")\n",
    "        #print(mfccs_audio)\n",
    "        #print(\"-----------------------------\")\n",
    "        \n",
    "        #print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "    return mfccsFit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN=fitMFFCs(X_TRAIN)\n",
    "X_TEST=fitMFFCs(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.05 GiB for an array with shape (3726, 14000, 13) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4dd1f54b523b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_TRAIN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_TRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_TEST\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_TEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras-gpu\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.05 GiB for an array with shape (3726, 14000, 13) and data type float64"
     ]
    }
   ],
   "source": [
    "X_TRAIN=numpy.asarray(X_TRAIN)\n",
    "X_TEST=numpy.asarray(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape)\n",
    "print(X_TRAIN[2500].shape)\n",
    "#print(X_TEST.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que nuestras salidas son los nombres de los idiomas, es necesario realizar una codificación de las salidas que son los nombres de los idiomas en texto [\"English\",\"Spanish...\"]antes de proceder con el entrenamiento, para ello se utilizara OneHotEncoder. Debido a que no podemos introducir textos en un modelo, es necesario transformar a valores numéricos.\n",
    "\n",
    "Debido a que los idiomas son independientes entre sí, se utilizará OneHotEncoder en lugar de LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from collections import Counter\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "Y_MFCCs_ENC = labelencoder.fit_transform(Y_MFCCs)\n",
    "Y_TEST_MFCCs_ENC = labelencoder.fit_transform(Y_TEST_MFCCs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MFCCs_HOT = to_categorical(Y_MFCCs_ENC)\n",
    "Y_TEST_MFCCs_HOT = to_categorical(Y_TEST_MFCCs_ENC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 1\n",
    "numClases=Y_MFCCs_HOT.shape[1]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "Y_MFCCs_ENC,Y_TEST_MFCCs_ENC= prepare_targets(Y_MFCCs, Y_TEST_MFCCs)\n",
    "#Y_MFCCs_HOT= tf.keras.utils.to_categorical(Y_MFCCs)\n",
    "#Y_TEST_MFCCs_HOT = tf.keras.utils.to_categorical(Y_TEST_MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_MFCCs_HOT[555])\n",
    "print(Y_TEST_MFCCs_HOT[250])\n",
    "print(Y_TEST_MFCCs[250])\n",
    "print(Y_MFCCs_HOT.shape[1])\n",
    "print(X_MFCCs.shape)\n",
    "\n",
    "\n",
    "X_TRAIN = X_TRAIN.reshape(X_TRAIN.shape[0], X_TRAIN.shape[1], X_TRAIN.shape[2], channel)\n",
    "X_TEST = X_TEST.reshape(X_TEST.shape[0], X_TEST.shape[1], X_TEST.shape[2], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(X_TRAIN.shape[1],X_TRAIN.shape[2],X_TRAIN.shape[3])))\n",
    "model.add(Dense(numClases, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_TRAIN, Y_MFCCs_HOT, epochs=epochs, validation_data=(X_TEST, Y_TEST_MFCCs_HOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(X_TRAIN.shape[1],X_TRAIN.shape[2],X_TRAIN.shape[3])))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(numClases, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.002, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# optimizer = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_TRAIN, Y_MFCCs_HOT, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_TEST, Y_TEST_MFCCs_HOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "import keraskeras.losses as ls\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Como no se cuenta con un número de muestras balanceado, se especifica este métogo\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}\n",
    "\n",
    "\n",
    "with tf.Session() as sess0:\n",
    "    assert not tf.executing_eagerly()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_shape=X_MFCCs.shape[1:], activation='tanh'))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments.\n",
    "    model.summary()\n",
    "  # history = model.fit(x=X_train_array, y=y_train_array, epochs=5, verbose=1, validation_split = 0.33, shuffle=True, class_weight=get_class_weights(pd.Series((list(set(labels))),dtype='category').cat.codes.values),batch_size=batch_size) \n",
    "    history = model.fit(x=X_MFCCs, y=Y_MFCCs_ENC, epochs=25, verbose=1, validation_split = 0.1, shuffle=True, class_weight=get_class_weights(Y_MFCCs_ENC),batch_size=128)\n",
    "    \n",
    "    model_evaluation = model.evaluate(x=X_TEST_MFCCs, y=Y_TEST_MFCCs_ENC, batch_size=None, verbose=1)\n",
    "\n",
    "    prediction = model.predict(X_TEST_MFCCs, batch_size = 128, verbose = 1)\n",
    "    \n",
    "    #april_tst = model.predict(mfcc_april_test, batch_size = 128, verbose = 1)\n",
    "\n",
    "    sess0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(13, 1, 1)\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_MFCCs_TRAIN, Y_MFCCs_HOT, batch_size=100, epochs=200, verbose=1, validation_data=(X_MFCCs_TEST, Y_TEST_MFCCs_HOT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- <a href=\"http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\">Mel Frequency Cepstral Coefficient (MFCC) tutorial</a> \n",
    "- <a href=\"https://www.researchgate.net/publication/330477843_A_Mel-Filterbank_and_MFCC-based_Neural_Network_Approach_to_Train_the_Houston_Toad_Call_Detection _System_Design\">A Mel-Filterbank and MFCC-based Neural Network Approach to Train the Houston Toad Call Detection System Design </a> \n",
    "- <a href=\"https://towardsdatascience.com/speech-recognition-analysis-f03ff9ce78e9\">Speech Recognition Analysis</a> \n",
    "- <a href=\"https://github.com/rctatman/getMFCCs/blob/master/getMFCCs.py\">getMFCCs</a> \n",
    "- <a href=\"https://towardsdatascience.com/how-to-apply-machine-learning-and-deep-learning-methods-to-audio-analysis-615e286fcbbc\">How to apply machine learning and deep learning methods to audio analysis</a>\n",
    "- <a href=\"https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\">Label Encoder vs. One Hot Encoder in Machine Learning</a>\n",
    "- <a href=\"https://www.kaggle.com/ashirahama/simple-keras-cnn-with-mfcc\">Simple Keras CNN with MFCC</a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
